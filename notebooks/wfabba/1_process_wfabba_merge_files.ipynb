{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2033d8b0",
   "metadata": {},
   "source": [
    "# Process WFABBA, Merge Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9337f228",
   "metadata": {},
   "source": [
    "<b>Summary:</b><br>\n",
    "Reads in raw WFABBA GOES-16 & WFABBA GOES-17 data from individual text files and outputs as combined csv files<br>\n",
    "\n",
    "- Parse WFABBA data from individual text files\n",
    "- Merge WFABBA data into unified csv files (based off of time and satellite name)\n",
    "\n",
    "<b>Output:</b><br>\n",
    "../..<br>\n",
    "└── data<br>\n",
    "&emsp;&emsp;&emsp;└── processed<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-16-2019.csv<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-17-2019.csv<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-16-2020.csv<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-17-2020.csv<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-16-2021.csv<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-17-2021.csv<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-16-Jan-2021.csv<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;└── GOES-17-Jan-2021.csv<br>\n",
    "\n",
    "<b>Instructions:</b><br>\n",
    "- See README.md in directory\n",
    "\n",
    "<b>Areas for Improvement:</b><br>\n",
    "Current processing time is about 3160 seconds. Need to consider faster processing methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3eb3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b476863-9d81-4c1f-a1b0-5c25ca367ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataColNames = [\"Algorithm\", \"Version\", \"Timestamp\", \"Satellite\", \"Instrument\", \"FlightModel\", \"ScanMode\", \"ProductType\", \"FileName\", \"DataSource\",\n",
    "               \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"MissingValueCode\"]\n",
    "\n",
    "dataColNames = ['Latitude', 'Longitude', 'Code', 'FRP', 'Fire Size', 'Fire Temp', 'Line', 'Element', 'Pixel Size',  'Obs BT4', 'Obs BT11', 'Bkg BT4', 'Bkg BT11', 'SolZen',  'SatZen', 'RelAzi', 'Eco']\n",
    "\n",
    "allColNames = metadataColNames + dataColNames\n",
    "rawDir = \"../../data/raw/wfabba/\"\n",
    "processedDir = \"../../data/processed/wfabba/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118ab288-0919-4e18-998f-283024ad212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOES-16-2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [41:30<00:00, 11.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2496.2598598003387\n",
      "==========================\n",
      "GOES-17-2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [41:15<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4981.038531780243\n",
      "==========================\n",
      "GOES-16-2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [1:11:55<00:00, 11.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9311.159327507019\n",
      "==========================\n",
      "GOES-17-2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/364 [00:05<17:36,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at ../../data/raw/wfabba/GOES-17-2020\\2020_01_01_001/GOES-17_SSEC2020run_6.5.012g.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364/364 [1:08:41<00:00, 11.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13447.257733106613\n",
      "==========================\n",
      "GOES-16-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [02:13<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13588.878423213959\n",
      "==========================\n",
      "GOES-17-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 339/339 [11:05<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14259.664109230042\n",
      "==========================\n",
      "GOES-16-Jan-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:37<00:00, 10.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14602.111042022705\n",
      "==========================\n",
      "GOES-17-Jan-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [05:09<00:00,  9.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14912.220679283142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/165 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "GOES-16-2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:42<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14955.231473445892\n",
      "==========================\n",
      "GOES-17-2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [01:46<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15062.290337562561\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "wfabba_dates = [\"GOES-16-2019\", \"GOES-17-2019\", \"GOES-16-2020\", \"GOES-17-2020\", \n",
    "    \"GOES-16-2021\", \"GOES-17-2021\", \"GOES-16-Jan-2021\", \"GOES-17-Jan-2021\", \"GOES-16-2022\", \"GOES-17-2022\"]\n",
    "\n",
    "for wfabba_date in wfabba_dates:\n",
    "    masterArr = []\n",
    "    print(wfabba_date)\n",
    "\n",
    "    targetDir = \"../../data/raw/wfabba/\" + wfabba_date\n",
    "\n",
    "    # recursively visit every directory of raw data\n",
    "    for root, subdirs, files in tqdm(sorted(os.walk(targetDir))):\n",
    "        # print(root)\n",
    "        # print(len(masterArr))\n",
    "\n",
    "        #if there are any files in the directory to parse\n",
    "        if len(files) > 0:\n",
    "            # process files with .GOES-16, .GOES-17, .GOES-16.txt, or .GOES-17.txt\n",
    "            if files[0][-8:] == \".GOES-16\" or files[0][-8:] == \".GOES-17\" or files[0][-12:] == \".GOES-16.txt\" or files[0][-12:] == \".GOES-17.txt\" :\n",
    "                #loop through each file\n",
    "                for file in files:\n",
    "                    filepath = root+\"/\"+file\n",
    "                    \n",
    "                    fo = open(filepath ,'r')\n",
    "                    metadataDict = {}\n",
    "                    dataArr = []\n",
    "                    lineCount = 0\n",
    "                    \n",
    "                    try:\n",
    "                        # read every line in the file\n",
    "                        for line in fo:\n",
    "                            \n",
    "                            # read in metadata\n",
    "                            if line[0:4] == \"### \":\n",
    "                                # logic for first 11 lines\n",
    "                                if lineCount < 11:\n",
    "                                    parseString = line[4:]\n",
    "                                    parseString = parseString.strip()\n",
    "                                    \n",
    "                                    # timestamp parsing logic\n",
    "                                    if parseString[0:4] == 'Date':\n",
    "                                        if parseString == \"Date: , Time:  UTC\":\n",
    "                                            break\n",
    "                                        year = parseString[6:10]\n",
    "                                        day_num = parseString[10:13]\n",
    "                                        hr = parseString[21:23]\n",
    "                                        min = parseString[24:26]\n",
    "                                        sec = parseString[27:29]\n",
    "                                        \n",
    "                                        #break out of loop if the timestamp data is all 0's\n",
    "                                        if year == \"0000\" and day_num == \"000\" and hr == \"00\" and min == \"00\" and sec == \"00\":\n",
    "                                            break\n",
    "                                        \n",
    "                                        # create timestamp from time data\n",
    "                                        res = dt.datetime.strptime(year + \"-\" + day_num + \" \" + hr + \":\" + min + \":\" + sec, \"%Y-%j %H:%M:%S\")\n",
    "                                        metadataDict[\"Timestamp\"] = res\n",
    "                                    else:\n",
    "                                        # parse column headers for data\n",
    "                                        splitData = parseString.split(\", \")\n",
    "                                        for item in splitData:\n",
    "                                            if item[-9:] == 'Algorithm':\n",
    "                                                metadataDict[\"Algorithm\"] = item\n",
    "                                            else:\n",
    "                                                sections = item.split(\":\")\n",
    "\n",
    "                                                if sections[0] == 'Flight Model':\n",
    "                                                    keyname = 'FlightModel'\n",
    "                                                elif sections[0] == 'Scan Mode':\n",
    "                                                    keyname = 'ScanMode'\n",
    "                                                elif sections[0] == 'Product type':\n",
    "                                                    keyname = 'ProductType'\n",
    "                                                elif sections[0] == 'Product/L2 filename':\n",
    "                                                    keyname = 'FileName'\n",
    "                                                elif sections[0] == 'Data source':\n",
    "                                                    keyname = 'DataSource'\n",
    "                                                elif sections[0] == 'Data creation time stamp':\n",
    "                                                    keyname = 'DataCreationTimestamp'\n",
    "                                                elif sections[0] == 'Navigation projection subpoint longitude':\n",
    "                                                    keyname = 'NavProjSubPtLong'\n",
    "                                                elif sections[0] == 'Actual satellite subpoint longitude':\n",
    "                                                    keyname = 'ActualSatSubPtLong'\n",
    "                                                elif sections[0] == 'Number of detected fires':\n",
    "                                                    keyname = 'NumFire'\n",
    "                                                elif sections[0] == 'Missing value code':\n",
    "                                                    keyname = 'MissingValueCode'\n",
    "                                                else:\n",
    "                                                    keyname = sections[0]\n",
    "\n",
    "                                                if len(sections) > 1:\n",
    "                                                    if sections[1] == '':\n",
    "                                                        value = None\n",
    "                                                    else:\n",
    "                                                        value = sections[1].strip()\n",
    "                                                    metadataDict[keyname] = value\n",
    "                                    lineCount+=1\n",
    "                            # parse the actual data\n",
    "                            elif line[0:3] != '###':\n",
    "                                line_list = line.replace(' ', '').replace(\"\\n\",\"\").split(',')\n",
    "                                app_dict = {dataColNames[i]: line_list[i] for i in range(len(dataColNames))}\n",
    "\n",
    "                                #keep 32 <= latitudes <= 35 and -123 <= longitude <= -113\n",
    "                                if (float(app_dict[\"Latitude\"]) >= 32) and (float(app_dict[\"Latitude\"]) <= 35) and (float(app_dict[\"Longitude\"]) >= -123) and (float(app_dict[\"Longitude\"]) <= -113):\n",
    "                                    dataArr.append(app_dict)\n",
    "                                    \n",
    "                    # error handling: print out the name of the file that is causing issues and break out of loop\n",
    "                    except:\n",
    "                        print(\"Error at \" + filepath)\n",
    "                        break\n",
    "                        \n",
    "                    # combine metadata and data into master array\n",
    "                    for dataDict in dataArr:\n",
    "                        allDataDict = {}\n",
    "                        allDataDict.update(metadataDict)\n",
    "                        allDataDict.update(dataDict)\n",
    "                        masterArr.append(allDataDict)\n",
    "                        \n",
    "                    fo.close()\n",
    "    \n",
    "    #create dataframe out of master array\n",
    "    df = pd.DataFrame(masterArr, columns=allColNames)\n",
    "    endtime = time.time()\n",
    "    print(endtime-starttime)\n",
    "    df.to_csv(processedDir + wfabba_date + \".csv\")\n",
    "    print(\"==========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f33670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
