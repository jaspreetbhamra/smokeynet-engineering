{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import datetime as dt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from haversine import haversine, Unit\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import pytz\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)\n",
    "p = print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup, Dataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds timestamps to nearest minute on the dot\n",
    "def round_secs(x):\n",
    "    x = x + timedelta(minutes = 1)\n",
    "    x = x.replace(second=0)\n",
    "    return x\n",
    "\n",
    "# determines if a WFABBA detection is within the same direction as the camera\n",
    "def is_in_camera_direction(camera_geometry_pt, direction, wfabba_geometry_pt):\n",
    "    if direction == \"north\":\n",
    "        # Has to be true for the image to be in front of the camera\n",
    "        return wfabba_geometry_pt.y >= camera_geometry_pt.y\n",
    "    elif direction == \"south\":\n",
    "        return wfabba_geometry_pt.y <= camera_geometry_pt.y\n",
    "    elif direction == \"east\":\n",
    "        return wfabba_geometry_pt.x >= camera_geometry_pt.x\n",
    "    elif direction == \"west\":\n",
    "        return wfabba_geometry_pt.x <= camera_geometry_pt.x\n",
    "    else:\n",
    "        # unknown or something else\n",
    "        pass\n",
    "    \n",
    "# finds any matches with specified WFABBA dataset based off of \n",
    "# whether distance to camera is within specified radius & camera direction\n",
    "def matches_distance_prox(camera_geometry, direction, radius_miles, wfabba_df):    \n",
    "    wfabba_df[\"distance_m\"] = wfabba_df[\"geometry\"].distance(camera_geometry)\n",
    "    wfabba_df[\"distance_mi\"] = wfabba_df[\"distance_m\"]/1609.344        \n",
    "    match_results_df = wfabba_df[(wfabba_df[\"distance_mi\"] <= radius_miles)].copy()\n",
    "    \n",
    "    #filter for detections within same direction\n",
    "    match_results_df[\"is_in_direction\"] = match_results_df.apply(\n",
    "        lambda row: is_in_camera_direction(camera_geometry, direction, row[\"geometry\"]), axis=1\n",
    "    )\n",
    "    match_results_df = match_results_df[match_results_df[\"is_in_direction\"] == True]\n",
    "\n",
    "    return match_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704f8edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93784\n",
      "92739\n",
      "376689\n",
      "334881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['69bravo-e-mobo-c', 'bh-w-mobo-c', 'bl-n-mobo-c', 'bl-s-mobo-c',\n",
       "       'bm-e-mobo-c', 'bm-w-mobo-c', 'cp-s-mobo-c', 'dwpgm-n-mobo-c',\n",
       "       'hp-e-mobo-c', 'hp-n-mobo-c', 'hp-s-mobo-c', 'hp-w-mobo-c',\n",
       "       'lo-s-mobo-c', 'lp-e-mobo-c', 'lp-n-mobo-c', 'lp-s-mobo',\n",
       "       'lp-s-mobo-c', 'lp-w-mobo-c', 'marconi-n-mobo-c', 'mg-n-mobo-c',\n",
       "       'ml-s-mobo-c', 'ml-w-mobo-c', 'mlo-n-mobo-c', 'mlo-s-mobo-c',\n",
       "       'om-e-mobo-c', 'om-n-mobo-c', 'om-s-mobo', 'om-s-mobo-c',\n",
       "       'om-w-mobo', 'om-w-mobo-c', 'pi-e-mobo-c', 'pi-n-mobo-c',\n",
       "       'pi-s-mobo', 'pi-s-mobo-c', 'pi-w-mobo-c', 'rm-e-mobo-c',\n",
       "       'rm-n-mobo-c', 'rm-w-mobo-c', 'sclm-e-mobo-c', 'sjh-n-mobo-c',\n",
       "       'sm-e-mobo-c', 'sm-n-mobo-c', 'sm-s-mobo-c', 'sm-w-mobo-c',\n",
       "       'smer-tcs8-mobo-c', 'smer-tcs9-mobo-c', 'so-w-mobo-c',\n",
       "       'sp-n-mobo-c', 'syp-w-mobo-c', 'tp-s-mobo-c', 'tp-w-mobo-c',\n",
       "       'vo-n-mobo-c', 'wc-e-mobo-c', 'wc-n-mobo-c', 'wc-s-mobo-c'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definte the processed and raw data directories\n",
    "processed_data_dir = \"../../data/processed/wfabba/\"\n",
    "raw_data_dir = \"../../data/raw/\"\n",
    "# read in GOES 16 inputs\n",
    "wfabba_goes_16_2019_df = pd.read_csv(processed_data_dir + \"GOES-16-2019.csv\")\n",
    "wfabba_goes_16_2020_df = pd.read_csv(processed_data_dir + \"GOES-16-2020.csv\")\n",
    "wfabba_goes_16_jan_2021_df = pd.read_csv(processed_data_dir + \"GOES-16-Jan-2021.csv\")\n",
    "wfabba_goes_16_2021_df = pd.read_csv(processed_data_dir + \"GOES-16-2021.csv\")\n",
    "wfabba_goes_16_2022_df = pd.read_csv(processed_data_dir + \"GOES-16-2022.csv\")\n",
    "# get rid of unnecessary columns including ones which contain the same values or all NaN\n",
    "wfabba_goes_16_2019_df = wfabba_goes_16_2019_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_16_2020_df = wfabba_goes_16_2020_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_16_jan_2021_df = wfabba_goes_16_jan_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2021 detections\n",
    "wfabba_goes_16_2022_df = wfabba_goes_16_2022_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2022 detections\n",
    "# filter out any January data in wfabba_goes_16_2021_df since it already exists in wfabba_goes_16_jan_2021_df\n",
    "print(len(wfabba_goes_16_2021_df))\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df[wfabba_goes_16_2021_df[\"Timestamp\"] >= \"2021-02-01\"]\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df.reset_index()\n",
    "wfabba_goes_16_2021_df = wfabba_goes_16_2021_df.drop(columns=[\"index\"])\n",
    "print(len(wfabba_goes_16_2021_df))\n",
    "# wfabba_goes_16_2021_df\n",
    "# join all GOES-16 dataframes into unified wfabba_goes_16_df\n",
    "wfabba_goes_16_df = pd.concat([wfabba_goes_16_2019_df, wfabba_goes_16_2020_df, wfabba_goes_16_jan_2021_df, wfabba_goes_16_2021_df, wfabba_goes_16_2022_df])\n",
    "wfabba_goes_16_df[\"timestamp_converted\"] = pd.to_datetime(wfabba_goes_16_df[\"Timestamp\"], infer_datetime_format=True, origin=\"unix\", utc=True)\n",
    "wfabba_goes_16_df = wfabba_goes_16_df.reset_index()\n",
    "wfabba_goes_16_df = wfabba_goes_16_df.drop(columns=[\"index\"])\n",
    "# wfabba_goes_16_df\n",
    "#read in GOES 17 inputs\n",
    "wfabba_goes_17_2019_df = pd.read_csv(processed_data_dir + \"GOES-17-2019.csv\")\n",
    "wfabba_goes_17_2020_df = pd.read_csv(processed_data_dir + \"GOES-17-2020.csv\")\n",
    "wfabba_goes_17_jan_2021_df = pd.read_csv(processed_data_dir + \"GOES-17-Jan-2021.csv\")\n",
    "wfabba_goes_17_2021_df = pd.read_csv(processed_data_dir + \"GOES-17-2021.csv\")\n",
    "wfabba_goes_17_2022_df = pd.read_csv(processed_data_dir + \"GOES-17-2022.csv\")\n",
    "#get rid of unnecessary columns including ones which contain the same values or all NaN\n",
    "wfabba_goes_17_2019_df = wfabba_goes_17_2019_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_17_2020_df = wfabba_goes_17_2020_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_17_jan_2021_df = wfabba_goes_17_jan_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"])\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2021 detections\n",
    "wfabba_goes_17_2022_df = wfabba_goes_17_2022_df.drop(columns = [\"Unnamed: 0\", \"Algorithm\",\"Instrument\",\"DataSource\", \"DataCreationTimestamp\", \"NavProjSubPtLong\", \"ActualSatSubPtLong\", \"NumFire\", \"Line\", \"Element\"]) #2022 detections\n",
    "# filter out any January data in wfabba_goes_17_2021_df since it already exists in wfabba_goes_17_jan_2021_df\n",
    "print(len(wfabba_goes_17_2021_df))\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df[wfabba_goes_17_2021_df[\"Timestamp\"] >= \"2021-02-01\"]\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df.reset_index()\n",
    "wfabba_goes_17_2021_df = wfabba_goes_17_2021_df.drop(columns=[\"index\"])\n",
    "print(len(wfabba_goes_17_2021_df))\n",
    "# wfabba_goes_17_2021_df\n",
    "# join all GOES-17 dataframes into unified wfabba_goes_17_df\n",
    "wfabba_goes_17_df = pd.concat([wfabba_goes_17_2019_df, wfabba_goes_17_2020_df, wfabba_goes_17_jan_2021_df, wfabba_goes_17_2021_df, wfabba_goes_17_2022_df])\n",
    "wfabba_goes_17_df[\"timestamp_converted\"] = pd.to_datetime(wfabba_goes_17_df[\"Timestamp\"], infer_datetime_format=True, origin=\"unix\", utc=True)\n",
    "wfabba_goes_17_df = wfabba_goes_17_df.reset_index()\n",
    "wfabba_goes_17_df = wfabba_goes_17_df.drop(columns=[\"index\"])\n",
    "# wfabba_goes_17_df\n",
    "#convert WFABBA GOES 16 coordinates from EPSG 4326 to EPSG 3310\n",
    "coords = [Point(xy) for xy in zip(wfabba_goes_16_df['Longitude'], wfabba_goes_16_df['Latitude'])]\n",
    "wfabba_goes_16_df = GeoDataFrame(wfabba_goes_16_df, crs = \"EPSG:4326\", geometry = coords) \n",
    "wfabba_goes_16_df = wfabba_goes_16_df.to_crs('EPSG:3310')\n",
    "# wfabba_goes_16_df[[\"Latitude\",\"Longitude\",\"geometry\"]]\n",
    "#convert WFABBA GOES 17 coordinates from EPSG 4326 to EPSG 3310\n",
    "coords = [Point(xy) for xy in zip(wfabba_goes_17_df['Longitude'], wfabba_goes_17_df['Latitude'])]\n",
    "wfabba_goes_17_df = GeoDataFrame(wfabba_goes_17_df, crs = \"EPSG:4326\", geometry = coords) \n",
    "wfabba_goes_17_df = wfabba_goes_17_df.to_crs('EPSG:3310')\n",
    "# wfabba_goes_17_df[[\"Latitude\",\"Longitude\",\"geometry\"]]\n",
    "# read in camera metadata\n",
    "camera_metadata_df = pd.read_csv(\"../../data/processed/camera_metadata_hpwren.csv\")\n",
    "# camera_metadata_df\n",
    "# read in camera metadata\n",
    "camera_metadata_df = pd.read_csv(\"../../data/processed/camera_image_id_mappings.csv\")\n",
    "# camera_metadata_df\n",
    "#Create dataframe for every minute of specified time period\n",
    "times = []\n",
    "start = datetime(2019, 6 , 1, 0, 0, 0, 0, pytz.UTC)\n",
    "end = datetime(2021, 7, 11, 23, 59, 0, 0, pytz.UTC)\n",
    "\n",
    "while start <= end:\n",
    "    times.append(start)\n",
    "    start = start + timedelta(minutes = 1)\n",
    "\n",
    "minutes_df = pd.DataFrame(times, columns = [\"timestamp\"])\n",
    "# minutes_df\n",
    "# Create testing SmokeyNet df\n",
    "df_test = pd.read_json(raw_data_dir + \"smokeynet_test.json\", orient=\"index\").reset_index().rename(columns={\"index\":\"filepath\"})\n",
    "df_test[\"type\"] = \"test\"\n",
    "# df_test\n",
    "#Create validating SmokeyNet df\n",
    "df_valid = pd.read_json(raw_data_dir + \"smokeynet_valid.json\", orient=\"index\").reset_index().rename(columns={\"index\":\"filepath\"})\n",
    "df_valid[\"type\"] = \"valid\"\n",
    "# df_valid\n",
    "#Join the SmokeyNet DFs together. For now just joining validation and test DFs\n",
    "df_labels = pd.concat([df_test, df_valid]).reset_index().drop(columns = [\"index\"])\n",
    "# df_labels\n",
    "# set the date and year columns\n",
    "df_labels[\"date\"] = df_labels[\"camera_name\"].str.split(\"_\", n=1, expand=True)[0]\n",
    "df_labels[\"year\"] = df_labels[\"date\"].str[:4]\n",
    "df_labels[\"date\"] = pd.to_datetime(df_labels[\"date\"])\n",
    "# df_labels\n",
    "# keeping only entries from 2019-06-01 onwards\n",
    "df_labels_filtered = df_labels[df_labels[\"date\"] >= \"2019-06-01\"].reset_index().drop(columns=[\"index\"])\n",
    "# df_labels_filtered\n",
    "#create time, datetime, event_name, camera_name attributes\n",
    "df_labels_filtered[\"time\"] = df_labels_filtered[\"filepath\"].str.split(\"/\").str[1]\n",
    "df_labels_filtered[\"time\"] = df_labels_filtered[\"time\"].str.split(\"_\").str[0]\n",
    "df_labels_filtered[\"datetime\"] = pd.to_datetime(df_labels_filtered[\"time\"], unit=\"s\", origin=\"unix\", utc=True)\n",
    "df_labels_filtered[\"event_name\"] = df_labels_filtered[\"filepath\"].str.split(\"/\").str[0]\n",
    "df_labels_filtered[\"camera_name\"] = df_labels_filtered[\"camera_name\"].str.split(\"_\").str[-1]\n",
    "# df_labels_filtered\n",
    "# join SmokeyNet data with camera metadata\n",
    "df_labels_filtered = df_labels_filtered.merge(camera_metadata_df, left_on=\"camera_name\", right_on=\"image_id\", how=\"left\")\n",
    "# df_labels_filtered\n",
    "# convert joined SmokeyNet-camera metadata dataframe's coordinates from EPSG 4326 to EPSG 3310\n",
    "coords = [Point(xy) for xy in zip(df_labels_filtered['long'], df_labels_filtered['lat'])]\n",
    "df_labels_filtered = GeoDataFrame(df_labels_filtered, crs = \"EPSG:4326\", geometry = coords) \n",
    "df_labels_filtered = df_labels_filtered.to_crs('EPSG:3310')\n",
    "# df_labels_filtered\n",
    "# round the SmokeyNet timestamps to nearest minute on the dot\n",
    "df_labels_filtered[\"datetime_rounded\"] = df_labels_filtered[\"datetime\"].apply(lambda x: round_secs(x))\n",
    "# df_labels_filtered\n",
    "# get all unique cameras being considered\n",
    "unique_cameras = df_labels_filtered[\"camera_name\"].unique()\n",
    "# unique_cameras\n",
    "# if there are cameras that don't have associated directions, filter them out\n",
    "unusable_cameras = df_labels_filtered[df_labels_filtered[\"direction\"].isna()][\"camera_name\"].unique()\n",
    "unique_cameras = np.setdiff1d(unique_cameras, unusable_cameras)\n",
    "unique_cameras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Version', 'Timestamp', 'Satellite', 'FlightModel', 'ScanMode',\n",
       "       'ProductType', 'FileName', 'MissingValueCode', 'Latitude', 'Longitude',\n",
       "       'Code', 'FRP', 'Fire Size', 'Fire Temp', 'Pixel Size', 'Obs BT4',\n",
       "       'Obs BT11', 'Bkg BT4', 'Bkg BT11', 'SolZen', 'SatZen', 'RelAzi', 'Eco',\n",
       "       'timestamp_converted', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfabba_goes_16_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At what point is there a recorded positive GOES observation given there is a fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "\n",
    "df_labels_filtered.head()\n",
    "distance_miles = 35\n",
    "# camera_metadata_df.head()\n",
    "# wfabba_goes_16_df.head()\n",
    "wfabba_goes_16_df.Code.value_counts()\n",
    "wfabba_goes_16_df.loc[(wfabba_goes_16_df.Code == 11) & (wfabba_goes_16_df[\"Fire Size\"] == 0.0) & (wfabba_goes_16_df[\"Fire Temp\"] == 0.0)].head()\n",
    "wfabba_goes_16_df.loc[(wfabba_goes_16_df[\"Fire Temp\"] < 0)][\"Code\"].value_counts() # [12, 13, 14, 15]\n",
    "wfabba_goes_16_df.loc[~wfabba_goes_16_df.geometry.isna()].shape[0], wfabba_goes_16_df.shape[0]\n",
    "wfabba_goes_16_df[(wfabba_goes_16_df[\"Timestamp\"] >= \"2019-08-13 21:00:00+00:00\") \n",
    "    & (wfabba_goes_16_df[\"Timestamp\"] <= \"2019-08-13 21:50:00+00:00\") \n",
    "    & (wfabba_goes_16_df[\"distance_mi\"] <= distance_miles)].head()      # Fire observed at 20th minute\n",
    "# wfabba_goes_16_df\n",
    "# wfabba_goes_16_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "# Timestamp = 2020-10-13 23:45:00+00:00\n",
    "wfabba_goes_16_df[(wfabba_goes_16_df[\"Timestamp\"] >= \"2020-10-13 23:15:00+00:00\") \n",
    "    & (wfabba_goes_16_df[\"Timestamp\"] <= \"2020-10-14 00:15:00+00:00\") \n",
    "    & (wfabba_goes_16_df[\"distance_mi\"] <= 60)].head()      # Fire observed at 45th minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The provided wfabba data contains fires with codes 10-15 only\n",
    "#### No observation has been tagged with the high confidence temporally filtered fire codes (30-35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random\n",
    "camera = \"69bravo-e-mobo-c\"\n",
    "distance_miles = 35\n",
    "camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "camera_instance = camera_df.iloc[0]\n",
    "goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "print (\"$\", goes_16_dist_match_df.shape[0], wfabba_goes_16_df.shape[0], camera_df.shape[0])\n",
    "goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "print (\"#\", goes_16_dist_match_df[goes_16_dist_match_df.duplicated(\"timestamp_converted_rounded\")].shape[0])\n",
    "print (\"*\", goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"]).shape[0])\n",
    "goes_16_dist_match_df[goes_16_dist_match_df.duplicated(\"timestamp_converted_rounded\")].sort_values(\"timestamp_converted_rounded\")[\"timestamp_converted_rounded\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join smokeynet predictions with the minute_df for a given camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_filtered.head()\n",
    "wfabba_goes_16_df.head()\n",
    "\n",
    "distance_miles = 35\n",
    "# camera = 'lp-e-mobo-c' \n",
    "camera = unique_cameras[0]\n",
    "camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "camera_instance = camera_df.iloc[0]\n",
    "#Find GOES-16 matches\n",
    "goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "goes_16_dist_match_df = goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "#Find GOES-17 matches\n",
    "goes_17_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_17_df)\n",
    "goes_17_dist_match_df[\"timestamp_converted_rounded\"] = goes_17_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "goes_17_dist_match_df = goes_17_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "#SmokeyNet_join --> changed join type to right so as to only keep non null values --> change back to left after testing\n",
    "test_df = minutes_df.merge(camera_df, left_on = \"timestamp\", right_on = \"datetime_rounded\",how=\"right\")\n",
    "test_df = test_df.rename(columns = {\"geometry\":\"HPWREN_Station_geometry\", \"lat\":\"HPWREN_lat\", \"long\":\"HPWREN_long\", \"datetime_rounded\":\"SmokeyNet_datetime_rounded\"})\n",
    "# print(\"joined SmokeyNet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_df.date.value_counts())\n",
    "df_labels_filtered.date.value_counts()\n",
    "print (min(df_labels_filtered.date), max(df_labels_filtered.date))\n",
    "print (camera_df.date.unique())\n",
    "print (min(df_labels_filtered.datetime_rounded.dt.date), max(df_labels_filtered.datetime_rounded.dt.date))\n",
    "test_df.date.value_counts()\n",
    "'2019-08-13' in goes_16_dist_match_df.timestamp_converted_rounded.dt.date\n",
    "blah = [x for x in goes_16_dist_match_df.timestamp_converted_rounded if datetime.strptime('2019-08-13', '%Y-%m-%d').date() == x.date()]\n",
    "print (blah)\n",
    "# datetime.strptime('2022', '%Y').year == datetime.now().year\n",
    "# datetime.strptime('2022-07-09', '%Y-%m-%d').date() == datetime.now().date()\n",
    "test_df[(test_df.image_gt == 1) & (test_df.timestamp == '2019-08-13 21:43:00+0000')].tail()\n",
    "goes_16_dist_match_df.timestamp_converted_rounded\n",
    "print ([x for x in test_df.timestamp if x in goes_16_dist_match_df.timestamp_converted_rounded])\n",
    "print (min(test_df.timestamp), min(goes_16_dist_match_df.timestamp_converted_rounded))\n",
    "print (max(test_df.timestamp), max(goes_16_dist_match_df.timestamp_converted_rounded))\n",
    "goes_16_dist_match_df.timestamp_converted_rounded\n",
    "[x for x in test_df.date if x in goes_16_dist_match_df.timestamp_converted_rounded.dt.date]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SmokeyNet Observations per camera\n",
    "### Extract number of unique dates when smokeynet predictions were generated per camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(e):\n",
    "    dates = e.datetime_rounded.dt.date\n",
    "    # camera_name = e.camera_name.iloc[0]\n",
    "    return pd.DataFrame({'camera_name': e.camera_name, 'no_of_unique_dates': len(dates.unique())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_name</th>\n",
       "      <th>min_time_for_camera</th>\n",
       "      <th>max_time_for_camera</th>\n",
       "      <th>no_of_unique_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lp-s-mobo-c</td>\n",
       "      <td>2019-07-12 13:43:00+00:00</td>\n",
       "      <td>2021-01-10 19:39:00+00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pi-s-mobo-c</td>\n",
       "      <td>2019-07-14 16:05:00+00:00</td>\n",
       "      <td>2021-01-13 21:51:00+00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pi-n-mobo-c</td>\n",
       "      <td>2020-03-06 17:04:00+00:00</td>\n",
       "      <td>2020-03-06 18:23:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml-w-mobo-c</td>\n",
       "      <td>2019-09-22 19:46:00+00:00</td>\n",
       "      <td>2019-10-06 18:28:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lo-s-mobo-c</td>\n",
       "      <td>2019-10-06 17:37:00+00:00</td>\n",
       "      <td>2019-10-06 18:56:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>om-e-mobo-c</td>\n",
       "      <td>2019-08-14 21:16:00+00:00</td>\n",
       "      <td>2020-11-05 22:57:00+00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lp-n-mobo-c</td>\n",
       "      <td>2019-09-13 23:32:00+00:00</td>\n",
       "      <td>2020-09-05 22:00:00+00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlo-s-mobo-c</td>\n",
       "      <td>2020-08-29 17:13:00+00:00</td>\n",
       "      <td>2021-01-13 21:49:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bh-w-mobo-c</td>\n",
       "      <td>2019-06-10 19:44:00+00:00</td>\n",
       "      <td>2019-10-01 21:20:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sm-e-mobo-c</td>\n",
       "      <td>2020-08-07 01:01:00+00:00</td>\n",
       "      <td>2020-09-05 22:00:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sm-s-mobo-c</td>\n",
       "      <td>2019-10-07 18:45:00+00:00</td>\n",
       "      <td>2020-08-28 16:20:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>om-w-mobo</td>\n",
       "      <td>2019-08-01 18:08:00+00:00</td>\n",
       "      <td>2019-08-01 19:27:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ml-s-mobo-c</td>\n",
       "      <td>2020-02-06 17:07:00+00:00</td>\n",
       "      <td>2020-03-06 18:12:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>om-s-mobo-c</td>\n",
       "      <td>2019-09-30 20:19:00+00:00</td>\n",
       "      <td>2019-10-07 21:14:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bm-w-mobo-c</td>\n",
       "      <td>2020-07-05 20:29:00+00:00</td>\n",
       "      <td>2020-07-05 21:48:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>so-w-mobo-c</td>\n",
       "      <td>2019-08-27 16:49:00+00:00</td>\n",
       "      <td>2019-08-27 18:08:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hp-e-mobo-c</td>\n",
       "      <td>2021-02-09 17:11:00+00:00</td>\n",
       "      <td>2021-02-09 18:30:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>om-w-mobo-c</td>\n",
       "      <td>2020-06-18 21:44:00+00:00</td>\n",
       "      <td>2021-01-07 19:12:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dwpgm-n-mobo-c</td>\n",
       "      <td>2020-08-12 21:58:00+00:00</td>\n",
       "      <td>2020-08-12 23:17:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hp-n-mobo-c</td>\n",
       "      <td>2020-07-09 19:14:00+00:00</td>\n",
       "      <td>2020-08-07 17:22:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rm-e-mobo-c</td>\n",
       "      <td>2020-02-26 18:05:00+00:00</td>\n",
       "      <td>2020-06-15 21:19:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cp-s-mobo-c</td>\n",
       "      <td>2020-08-29 17:19:00+00:00</td>\n",
       "      <td>2020-10-14 00:25:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tp-s-mobo-c</td>\n",
       "      <td>2021-02-04 18:31:00+00:00</td>\n",
       "      <td>2021-02-04 19:50:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>smer-tcs8-mobo-c</td>\n",
       "      <td>2019-08-29 16:31:00+00:00</td>\n",
       "      <td>2019-08-29 17:49:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wc-e-mobo-c</td>\n",
       "      <td>2019-09-24 21:21:00+00:00</td>\n",
       "      <td>2021-07-11 18:36:00+00:00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>wc-n-mobo-c</td>\n",
       "      <td>2019-10-05 20:39:00+00:00</td>\n",
       "      <td>2020-07-05 21:46:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rm-w-mobo-c</td>\n",
       "      <td>2019-08-26 19:11:00+00:00</td>\n",
       "      <td>2020-09-30 20:01:00+00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>smer-tcs9-mobo-c</td>\n",
       "      <td>2019-08-26 19:13:00+00:00</td>\n",
       "      <td>2019-10-01 18:42:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>wc-s-mobo-c</td>\n",
       "      <td>2019-09-24 21:19:00+00:00</td>\n",
       "      <td>2019-09-25 20:54:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sclm-e-mobo-c</td>\n",
       "      <td>2020-12-05 17:37:00+00:00</td>\n",
       "      <td>2020-12-05 18:56:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mg-n-mobo-c</td>\n",
       "      <td>2019-07-16 19:25:00+00:00</td>\n",
       "      <td>2019-07-16 20:44:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lp-w-mobo-c</td>\n",
       "      <td>2020-08-07 00:55:00+00:00</td>\n",
       "      <td>2020-12-16 22:15:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hp-s-mobo-c</td>\n",
       "      <td>2019-09-24 21:28:00+00:00</td>\n",
       "      <td>2019-09-24 22:47:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mlo-n-mobo-c</td>\n",
       "      <td>2020-03-06 16:53:00+00:00</td>\n",
       "      <td>2020-03-06 18:12:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pi-s-mobo</td>\n",
       "      <td>2019-08-09 16:58:00+00:00</td>\n",
       "      <td>2019-08-09 18:16:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pi-e-mobo-c</td>\n",
       "      <td>2019-08-29 21:55:00+00:00</td>\n",
       "      <td>2020-08-23 21:41:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>om-n-mobo-c</td>\n",
       "      <td>2019-10-06 17:11:00+00:00</td>\n",
       "      <td>2020-12-16 22:15:00+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sp-n-mobo-c</td>\n",
       "      <td>2020-08-13 21:23:00+00:00</td>\n",
       "      <td>2020-08-13 22:42:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>om-s-mobo</td>\n",
       "      <td>2019-08-03 21:15:00+00:00</td>\n",
       "      <td>2019-08-03 22:34:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sm-w-mobo-c</td>\n",
       "      <td>2019-08-25 20:47:00+00:00</td>\n",
       "      <td>2020-07-12 17:31:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rm-n-mobo-c</td>\n",
       "      <td>2019-09-15 20:44:00+00:00</td>\n",
       "      <td>2019-09-15 22:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>hp-w-mobo-c</td>\n",
       "      <td>2020-02-02 17:48:00+00:00</td>\n",
       "      <td>2020-02-02 19:07:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tp-w-mobo-c</td>\n",
       "      <td>2021-02-09 17:39:00+00:00</td>\n",
       "      <td>2021-02-09 18:58:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>69bravo-e-mobo-c</td>\n",
       "      <td>2019-08-13 20:41:00+00:00</td>\n",
       "      <td>2019-08-13 22:00:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pi-w-mobo-c</td>\n",
       "      <td>2019-09-24 21:19:00+00:00</td>\n",
       "      <td>2020-12-16 22:15:00+00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>sjh-n-mobo-c</td>\n",
       "      <td>2020-08-13 21:25:00+00:00</td>\n",
       "      <td>2020-08-13 22:44:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bl-n-mobo-c</td>\n",
       "      <td>2019-08-29 22:33:00+00:00</td>\n",
       "      <td>2019-08-29 23:52:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>lp-s-mobo</td>\n",
       "      <td>2019-08-14 21:20:00+00:00</td>\n",
       "      <td>2019-08-14 22:39:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>syp-w-mobo-c</td>\n",
       "      <td>2020-06-14 19:12:00+00:00</td>\n",
       "      <td>2020-06-14 20:31:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sm-n-mobo-c</td>\n",
       "      <td>2019-09-24 21:20:00+00:00</td>\n",
       "      <td>2020-12-16 22:14:00+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>vo-n-mobo-c</td>\n",
       "      <td>2019-10-05 20:33:00+00:00</td>\n",
       "      <td>2019-10-05 21:51:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>lp-e-mobo-c</td>\n",
       "      <td>2020-08-22 19:18:00+00:00</td>\n",
       "      <td>2020-08-22 20:37:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>bm-e-mobo-c</td>\n",
       "      <td>2019-10-05 20:39:00+00:00</td>\n",
       "      <td>2019-10-05 21:58:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>bl-s-mobo-c</td>\n",
       "      <td>2019-09-24 21:16:00+00:00</td>\n",
       "      <td>2019-09-24 22:35:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>marconi-n-mobo-c</td>\n",
       "      <td>2020-08-13 21:53:00+00:00</td>\n",
       "      <td>2020-08-13 23:12:00+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         camera_name       min_time_for_camera       max_time_for_camera  \\\n",
       "0        lp-s-mobo-c 2019-07-12 13:43:00+00:00 2021-01-10 19:39:00+00:00   \n",
       "1        pi-s-mobo-c 2019-07-14 16:05:00+00:00 2021-01-13 21:51:00+00:00   \n",
       "2        pi-n-mobo-c 2020-03-06 17:04:00+00:00 2020-03-06 18:23:00+00:00   \n",
       "3        ml-w-mobo-c 2019-09-22 19:46:00+00:00 2019-10-06 18:28:00+00:00   \n",
       "4        lo-s-mobo-c 2019-10-06 17:37:00+00:00 2019-10-06 18:56:00+00:00   \n",
       "5        om-e-mobo-c 2019-08-14 21:16:00+00:00 2020-11-05 22:57:00+00:00   \n",
       "6        lp-n-mobo-c 2019-09-13 23:32:00+00:00 2020-09-05 22:00:00+00:00   \n",
       "7       mlo-s-mobo-c 2020-08-29 17:13:00+00:00 2021-01-13 21:49:00+00:00   \n",
       "8        bh-w-mobo-c 2019-06-10 19:44:00+00:00 2019-10-01 21:20:00+00:00   \n",
       "9        sm-e-mobo-c 2020-08-07 01:01:00+00:00 2020-09-05 22:00:00+00:00   \n",
       "10       sm-s-mobo-c 2019-10-07 18:45:00+00:00 2020-08-28 16:20:00+00:00   \n",
       "11         om-w-mobo 2019-08-01 18:08:00+00:00 2019-08-01 19:27:00+00:00   \n",
       "12       ml-s-mobo-c 2020-02-06 17:07:00+00:00 2020-03-06 18:12:00+00:00   \n",
       "13       om-s-mobo-c 2019-09-30 20:19:00+00:00 2019-10-07 21:14:00+00:00   \n",
       "14       bm-w-mobo-c 2020-07-05 20:29:00+00:00 2020-07-05 21:48:00+00:00   \n",
       "15       so-w-mobo-c 2019-08-27 16:49:00+00:00 2019-08-27 18:08:00+00:00   \n",
       "16       hp-e-mobo-c 2021-02-09 17:11:00+00:00 2021-02-09 18:30:00+00:00   \n",
       "17       om-w-mobo-c 2020-06-18 21:44:00+00:00 2021-01-07 19:12:00+00:00   \n",
       "18    dwpgm-n-mobo-c 2020-08-12 21:58:00+00:00 2020-08-12 23:17:00+00:00   \n",
       "19       hp-n-mobo-c 2020-07-09 19:14:00+00:00 2020-08-07 17:22:00+00:00   \n",
       "20       rm-e-mobo-c 2020-02-26 18:05:00+00:00 2020-06-15 21:19:00+00:00   \n",
       "21       cp-s-mobo-c 2020-08-29 17:19:00+00:00 2020-10-14 00:25:00+00:00   \n",
       "22       tp-s-mobo-c 2021-02-04 18:31:00+00:00 2021-02-04 19:50:00+00:00   \n",
       "23  smer-tcs8-mobo-c 2019-08-29 16:31:00+00:00 2019-08-29 17:49:00+00:00   \n",
       "24       wc-e-mobo-c 2019-09-24 21:21:00+00:00 2021-07-11 18:36:00+00:00   \n",
       "25       wc-n-mobo-c 2019-10-05 20:39:00+00:00 2020-07-05 21:46:00+00:00   \n",
       "26       rm-w-mobo-c 2019-08-26 19:11:00+00:00 2020-09-30 20:01:00+00:00   \n",
       "27  smer-tcs9-mobo-c 2019-08-26 19:13:00+00:00 2019-10-01 18:42:00+00:00   \n",
       "28       wc-s-mobo-c 2019-09-24 21:19:00+00:00 2019-09-25 20:54:00+00:00   \n",
       "29     sclm-e-mobo-c 2020-12-05 17:37:00+00:00 2020-12-05 18:56:00+00:00   \n",
       "30       mg-n-mobo-c 2019-07-16 19:25:00+00:00 2019-07-16 20:44:00+00:00   \n",
       "31       lp-w-mobo-c 2020-08-07 00:55:00+00:00 2020-12-16 22:15:00+00:00   \n",
       "32       hp-s-mobo-c 2019-09-24 21:28:00+00:00 2019-09-24 22:47:00+00:00   \n",
       "33      mlo-n-mobo-c 2020-03-06 16:53:00+00:00 2020-03-06 18:12:00+00:00   \n",
       "34         pi-s-mobo 2019-08-09 16:58:00+00:00 2019-08-09 18:16:00+00:00   \n",
       "35       pi-e-mobo-c 2019-08-29 21:55:00+00:00 2020-08-23 21:41:00+00:00   \n",
       "36       om-n-mobo-c 2019-10-06 17:11:00+00:00 2020-12-16 22:15:00+00:00   \n",
       "37       sp-n-mobo-c 2020-08-13 21:23:00+00:00 2020-08-13 22:42:00+00:00   \n",
       "38         om-s-mobo 2019-08-03 21:15:00+00:00 2019-08-03 22:34:00+00:00   \n",
       "39       sm-w-mobo-c 2019-08-25 20:47:00+00:00 2020-07-12 17:31:00+00:00   \n",
       "40       rm-n-mobo-c 2019-09-15 20:44:00+00:00 2019-09-15 22:00:00+00:00   \n",
       "41       hp-w-mobo-c 2020-02-02 17:48:00+00:00 2020-02-02 19:07:00+00:00   \n",
       "42       tp-w-mobo-c 2021-02-09 17:39:00+00:00 2021-02-09 18:58:00+00:00   \n",
       "43  69bravo-e-mobo-c 2019-08-13 20:41:00+00:00 2019-08-13 22:00:00+00:00   \n",
       "44       pi-w-mobo-c 2019-09-24 21:19:00+00:00 2020-12-16 22:15:00+00:00   \n",
       "45      sjh-n-mobo-c 2020-08-13 21:25:00+00:00 2020-08-13 22:44:00+00:00   \n",
       "46       bl-n-mobo-c 2019-08-29 22:33:00+00:00 2019-08-29 23:52:00+00:00   \n",
       "47         lp-s-mobo 2019-08-14 21:20:00+00:00 2019-08-14 22:39:00+00:00   \n",
       "48      syp-w-mobo-c 2020-06-14 19:12:00+00:00 2020-06-14 20:31:00+00:00   \n",
       "49       sm-n-mobo-c 2019-09-24 21:20:00+00:00 2020-12-16 22:14:00+00:00   \n",
       "50       vo-n-mobo-c 2019-10-05 20:33:00+00:00 2019-10-05 21:51:00+00:00   \n",
       "51       lp-e-mobo-c 2020-08-22 19:18:00+00:00 2020-08-22 20:37:00+00:00   \n",
       "52       bm-e-mobo-c 2019-10-05 20:39:00+00:00 2019-10-05 21:58:00+00:00   \n",
       "53       bl-s-mobo-c 2019-09-24 21:16:00+00:00 2019-09-24 22:35:00+00:00   \n",
       "54  marconi-n-mobo-c 2020-08-13 21:53:00+00:00 2020-08-13 23:12:00+00:00   \n",
       "\n",
       "    no_of_unique_dates  \n",
       "0                    8  \n",
       "1                    6  \n",
       "2                    1  \n",
       "3                    3  \n",
       "4                    1  \n",
       "5                    5  \n",
       "6                    8  \n",
       "7                    2  \n",
       "8                    2  \n",
       "9                    2  \n",
       "10                   2  \n",
       "11                   1  \n",
       "12                   2  \n",
       "13                   3  \n",
       "14                   1  \n",
       "15                   1  \n",
       "16                   1  \n",
       "17                   3  \n",
       "18                   1  \n",
       "19                   2  \n",
       "20                   2  \n",
       "21                   3  \n",
       "22                   1  \n",
       "23                   1  \n",
       "24                   8  \n",
       "25                   2  \n",
       "26                   6  \n",
       "27                   2  \n",
       "28                   2  \n",
       "29                   1  \n",
       "30                   1  \n",
       "31                   3  \n",
       "32                   1  \n",
       "33                   1  \n",
       "34                   1  \n",
       "35                   2  \n",
       "36                   3  \n",
       "37                   1  \n",
       "38                   1  \n",
       "39                   2  \n",
       "40                   1  \n",
       "41                   1  \n",
       "42                   1  \n",
       "43                   1  \n",
       "44                   4  \n",
       "45                   1  \n",
       "46                   1  \n",
       "47                   1  \n",
       "48                   1  \n",
       "49                   2  \n",
       "50                   1  \n",
       "51                   1  \n",
       "52                   1  \n",
       "53                   1  \n",
       "54                   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_min_per_camera_df = pd.DataFrame(df_labels_filtered['camera_name'].unique())\n",
    "max_min_per_camera_df.columns = ['camera_name']\n",
    "max_min_per_camera_df = max_min_per_camera_df.merge(\n",
    "    df_labels_filtered[['camera_name', 'datetime_rounded']].groupby(by='camera_name').min(),\n",
    "    left_on='camera_name', right_on = 'camera_name',\n",
    "    how='left'\n",
    ").rename(columns = {'datetime_rounded':'min_time_for_camera'})\n",
    "max_min_per_camera_df = max_min_per_camera_df.merge(\n",
    "    df_labels_filtered[['camera_name', 'datetime_rounded']].groupby(by='camera_name').max(),\n",
    "    left_on='camera_name', right_on = 'camera_name',\n",
    "    how='left'\n",
    ").rename(columns = {'datetime_rounded':'max_time_for_camera'})\n",
    "max_min_per_camera_df = max_min_per_camera_df.merge(\n",
    "    df_labels_filtered[['camera_name', 'datetime_rounded']].groupby(by='camera_name').apply(extract_date).drop_duplicates(),\n",
    "    left_on='camera_name', right_on = 'camera_name',\n",
    "    how='left'\n",
    ")\n",
    "max_min_per_camera_df.head(55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique dates for goes observations after proximity matching per camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filepath', 'camera_name', 'image_gt', 'tile_gt', 'image_pred',\n",
       "       'tile_pred', 'type', 'date', 'year', 'time', 'datetime', 'event_name',\n",
       "       'camera_id', 'image_id', 'lat', 'long', 'direction', 'geometry',\n",
       "       'datetime_rounded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [10:21<00:00, 11.30s/it]\n"
     ]
    }
   ],
   "source": [
    "'''GOES columns : 'Version', 'Timestamp', 'Satellite', 'FlightModel', 'ScanMode',\n",
    "       'ProductType', 'FileName', 'MissingValueCode', 'Latitude', 'Longitude',\n",
    "       'Code', 'FRP', 'Fire Size', 'Fire Temp', 'Pixel Size', 'Obs BT4',\n",
    "       'Obs BT11', 'Bkg BT4', 'Bkg BT11', 'SolZen', 'SatZen', 'RelAzi', 'Eco',\n",
    "       'timestamp_converted', 'geometry', 'distance_m', 'distance_mi',\n",
    "       'is_in_direction'\n",
    "'''\n",
    "'''df_labels_filtered columns: 'filepath', 'camera_name', 'image_gt', 'tile_gt', 'image_pred',\n",
    "       'tile_pred', 'type', 'date', 'year', 'time', 'datetime', 'event_name',\n",
    "       'camera_id', 'image_id', 'lat', 'long', 'direction', 'geometry',\n",
    "       'datetime_rounded'\n",
    "'''\n",
    "distance_miles = 35\n",
    "\n",
    "smokey_net_camera_date = []\n",
    "goes_16_camera_date = []\n",
    "goes_17_camera_date = []\n",
    "\n",
    "for camera in tqdm(unique_cameras):\n",
    "    camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "    camera_instance = camera_df.iloc[0]\n",
    "    unique_dates = camera_df.date.unique()\n",
    "    smokey_net_camera_date += list(zip([camera]*len(unique_dates), unique_dates))\n",
    "    #Find GOES-16 matches\n",
    "    goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "    goes_16_dist_match_df['date_val'] = pd.to_datetime(goes_16_dist_match_df.Timestamp).dt.date\n",
    "    unique_dates = goes_16_dist_match_df.date_val.unique()\n",
    "    goes_16_camera_date += list(zip([camera]*len(unique_dates), unique_dates))\n",
    "    #Find GOES-17 matches\n",
    "    goes_17_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_17_df)\n",
    "    goes_17_dist_match_df['date_val'] = pd.to_datetime(goes_17_dist_match_df.Timestamp).dt.date\n",
    "    unique_dates = goes_17_dist_match_df.date_val.unique()\n",
    "    goes_17_camera_date += list(zip([camera]*len(unique_dates), unique_dates))\n",
    "\n",
    "smokey_net_camera_date_df = pd.DataFrame(smokey_net_camera_date, columns=['camera_name', 'smokey_net_dates'])\n",
    "goes_16_camera_date_df = pd.DataFrame(goes_16_camera_date, columns=['camera_name', 'goes16_dates'])\n",
    "goes_16_camera_date_df.goes16_dates = goes_16_camera_date_df.goes16_dates.astype('datetime64[ns]')\n",
    "goes_17_camera_date_df = pd.DataFrame(goes_17_camera_date, columns=['camera_name', 'goes17_dates'])\n",
    "goes_17_camera_date_df.goes17_dates = goes_17_camera_date_df.goes17_dates.astype('datetime64[ns]')\n",
    "\n",
    "agg_camera_date_df = smokey_net_camera_date_df.copy()\n",
    "agg_camera_date_df = agg_camera_date_df.merge(\n",
    "       goes_16_camera_date_df,\n",
    "       left_on=['camera_name', 'smokey_net_dates'],\n",
    "       right_on=['camera_name', 'goes16_dates'],\n",
    "       how='outer'\n",
    ")\n",
    "agg_camera_date_df = agg_camera_date_df.merge(\n",
    "       goes_17_camera_date_df,\n",
    "       left_on=['camera_name', 'smokey_net_dates'],\n",
    "       right_on=['camera_name', 'goes17_dates'],\n",
    "       how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_camera_date_df.to_csv('../../data/processed/agg_camera_date_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to test sliding window merge using pandas merge_asof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Version', 'Timestamp', 'Satellite', 'FlightModel', 'ScanMode',\n",
      "       'ProductType', 'FileName', 'MissingValueCode', 'Latitude', 'Longitude',\n",
      "       'Code', 'FRP', 'Fire Size', 'Fire Temp', 'Pixel Size', 'Obs BT4',\n",
      "       'Obs BT11', 'Bkg BT4', 'Bkg BT11', 'SolZen', 'SatZen', 'RelAzi', 'Eco',\n",
      "       'timestamp_converted', 'geometry'],\n",
      "      dtype='object')\n",
      "Index(['filepath', 'camera_name', 'image_gt', 'tile_gt', 'image_pred',\n",
      "       'tile_pred', 'type', 'date', 'year', 'time', 'datetime', 'event_name',\n",
      "       'camera_id', 'image_id', 'lat', 'long', 'direction', 'geometry',\n",
      "       'datetime_rounded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (wfabba_goes_16_df.columns)\n",
    "print (df_labels_filtered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:17<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Original method, for comparison\n",
    "for camera in tqdm(unique_cameras):\n",
    "    \n",
    "    # print(\"Camera:\",camera)\n",
    "    camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "\n",
    "    camera_instance = camera_df.iloc[0]\n",
    "    \n",
    "    #Find GOES-16 matches\n",
    "    goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "    goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_16_dist_match_df = goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    #Find GOES-17 matches\n",
    "    goes_17_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_17_df)\n",
    "    goes_17_dist_match_df[\"timestamp_converted_rounded\"] = goes_17_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_17_dist_match_df = goes_17_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    #SmokeyNet_join\n",
    "    test_df = minutes_df.merge(camera_df, left_on = \"timestamp\", right_on = \"datetime_rounded\",how=\"left\")\n",
    "    test_df = test_df.rename(columns = {\"geometry\":\"HPWREN_Station_geometry\", \"lat\":\"HPWREN_lat\", \"long\":\"HPWREN_long\", \"datetime_rounded\":\"SmokeyNet_datetime_rounded\"})\n",
    "    # print(\"joined SmokeyNet\")\n",
    "    \n",
    "    #GOES-16 Join\n",
    "    test_df = test_df.merge(goes_16_dist_match_df[[\"timestamp_converted_rounded\", \"geometry\", \"Code\"]], left_on = \"timestamp\", right_on = \"timestamp_converted_rounded\",how=\"left\")\n",
    "    test_df = test_df.rename(columns = {\"geometry\":\"WFABBA_GOES16_geometry\", \"timestamp_converted_rounded\":\"WFABBA_GOES16_timestamp_converted_rounded\", \"Code\":\"WFABBA_GOES16_Code\"})\n",
    "    test_df = test_df[[\"timestamp\",\"camera_name\", \"image_gt\", \"image_pred\", \"type\", \"WFABBA_GOES16_geometry\", \"WFABBA_GOES16_Code\"]]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] != None,'goes16_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES16_geometry\"] == None,'goes16_pred'] = 0\n",
    "    # print(\"joined GOES16\")\n",
    "\n",
    "    #GOES-17 Join\n",
    "    test_df = test_df.merge(goes_17_dist_match_df[[\"timestamp_converted_rounded\", \"geometry\", \"Code\"]], left_on = \"timestamp\", right_on = \"timestamp_converted_rounded\",how=\"left\")\n",
    "    test_df = test_df.rename(columns = {\"geometry\":\"WFABBA_GOES17_geometry\", \"timestamp_converted_rounded\":\"WFABBA_GOES17_timestamp_converted_rounded\", \"Code\":\"WFABBA_GOES17_Code\"})\n",
    "    test_df = test_df[[\"timestamp\",\"camera_name\", \"image_gt\", \"image_pred\", \"type\", \"WFABBA_GOES16_geometry\", \"goes16_pred\", \"WFABBA_GOES17_geometry\", \"WFABBA_GOES16_Code\", \"WFABBA_GOES17_Code\"]]\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] != None,'goes17_pred'] = 1\n",
    "    test_df.loc[test_df[\"WFABBA_GOES17_geometry\"] == None,'goes17_pred'] = 0\n",
    "    # print(\"joined GOES17\")\n",
    "\n",
    "    #Get all votes and determine if smoke was detected by majority rule\n",
    "    test_df[\"final_vote\"] = test_df[\"image_pred\"] + test_df[\"goes16_pred\"] + test_df[\"goes17_pred\"]\n",
    "    test_df.loc[test_df[\"final_vote\"] >= 2,'final_pred'] = 1\n",
    "    test_df.loc[test_df[\"final_vote\"] < 2,'final_pred'] = 0\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print (sum(test_df.loc[test_df['camera_name'] == unique_cameras[0]].goes16_pred == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_miles = 35\n",
    "\n",
    "for camera in unique_cameras:\n",
    "    camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "    camera_instance = camera_df.iloc[0]\n",
    "    \n",
    "    #Find GOES-16 matches\n",
    "    goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "    goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_16_dist_match_df = goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    camera_df.sort_values(by=['datetime_rounded'], inplace=True)\n",
    "    goes_16_dist_match_df.sort_values(by=['timestamp_converted_rounded'], inplace=True)\n",
    "\n",
    "    temp_df = pd.merge_asof(\n",
    "        left=camera_df,\n",
    "        right=goes_16_dist_match_df,\n",
    "        left_on='datetime_rounded',\n",
    "        right_on='timestamp_converted_rounded',\n",
    "        tolerance=pd.Timedelta(minutes=60),\n",
    "        direction='forward'\n",
    "    )\n",
    "\n",
    "    temp_df.loc[temp_df[\"geometry_y\"] != None,'goes16_pred'] = 1\n",
    "    temp_df.loc[temp_df[\"geometry_y\"] == None,'goes16_pred'] = 0\n",
    "    temp_df.head()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_rounded</th>\n",
       "      <th>image_gt</th>\n",
       "      <th>image_pred</th>\n",
       "      <th>timestamp_converted_rounded</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>goes16_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-08-13 21:20:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-08-13 21:21:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-08-13 21:22:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            datetime_rounded  image_gt  image_pred  \\\n",
       "39 2019-08-13 21:20:00+00:00         1           0   \n",
       "40 2019-08-13 21:21:00+00:00         1           1   \n",
       "41 2019-08-13 21:22:00+00:00         1           1   \n",
       "\n",
       "   timestamp_converted_rounded time_diff  goes16_pred  \n",
       "39                         NaT       NaT          0.0  \n",
       "40                         NaT       NaT          0.0  \n",
       "41                         NaT       NaT          0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (sum(temp_df.goes16_pred == 0))\n",
    "temp_df.head(80)\n",
    "temp_df.columns\n",
    "temp_df['time_diff'] = temp_df['timestamp_converted_rounded'] - temp_df['datetime_rounded']\n",
    "temp_df[['datetime_rounded', 'image_gt', 'image_pred', 'timestamp_converted_rounded', 'time_diff', 'goes16_pred']].loc[(temp_df.goes16_pred == 0) & (temp_df.image_gt == 1)].head(80)\n",
    "# temp_df[['datetime_rounded', 'image_gt', 'image_pred', 'timestamp_converted_rounded', 'time_diff', 'goes16_pred']].loc[(temp_df.goes16_pred != 0)].head(80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual join\n",
    "print (test_df.shape)\n",
    "print (goes_16_dist_match_df.shape)\n",
    "test_df.head()\n",
    "# max(list(camera_df.datetime_rounded)), max(list(minutes_df.timestamp))\n",
    "# df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].shape\n",
    "# setting the offset to 10 minutes before and after the current time\n",
    "offset = 20\n",
    "for index, a_row in test_df.iterrows():\n",
    "    curr_time = a_row['timestamp']\n",
    "    temp_df = goes_16_dist_match_df[\n",
    "        (goes_16_dist_match_df.timestamp_converted_rounded >= (curr_time - timedelta(minutes=offset)))\n",
    "        &\n",
    "        (goes_16_dist_match_df.timestamp_converted_rounded <= (curr_time + timedelta(minutes=offset)))\n",
    "    ]\n",
    "    print (temp_df.head())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time difference between first positive ground truth and first positive goes detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filepath', 'camera_name', 'image_gt', 'tile_gt', 'image_pred',\n",
       "       'tile_pred', 'type', 'date', 'year', 'time', 'datetime', 'event_name',\n",
       "       'camera_id', 'image_id', 'lat', 'long', 'direction', 'geometry',\n",
       "       'datetime_rounded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(\"lp-s-mobo-c\")].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [10:32<00:00, 11.50s/it]\n"
     ]
    }
   ],
   "source": [
    "def fetch_first_positive_obs(e):\n",
    "    temp = e.loc[(e.image_gt == 1)].iloc[0][['event_name', 'datetime_rounded']].to_list()\n",
    "    return pd.Series({'event_name': temp[0], 'datetime_rounded': temp[1]})\n",
    "\n",
    "distance_miles = 35\n",
    "\n",
    "obs_list = []\n",
    "\n",
    "for camera in tqdm(unique_cameras):\n",
    "    # camera = 'lp-s-mobo-c'\n",
    "    camera_df = df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(camera)].copy()\n",
    "    camera_instance = camera_df.iloc[0]\n",
    "    \n",
    "    #Find GOES-16 matches\n",
    "    goes_16_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_16_df)\n",
    "    goes_16_dist_match_df[\"timestamp_converted_rounded\"] = goes_16_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_16_dist_match_df = goes_16_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    #Find GOES-17 matches\n",
    "    goes_17_dist_match_df = matches_distance_prox(camera_instance[\"geometry\"], camera_instance[\"direction\"], distance_miles, wfabba_goes_17_df)\n",
    "    goes_17_dist_match_df[\"timestamp_converted_rounded\"] = goes_17_dist_match_df[\"timestamp_converted\"].apply(lambda x: round_secs(x))\n",
    "    goes_17_dist_match_df = goes_17_dist_match_df.drop_duplicates(subset = [\"timestamp_converted_rounded\"], keep=\"last\")\n",
    "\n",
    "    # Sort by event_name as well --> since not doing so could mess up order of images in the sequence\n",
    "    camera_df.sort_values(by=['event_name', 'datetime_rounded'], inplace=True)\n",
    "    goes_16_dist_match_df.sort_values(by=['timestamp_converted_rounded'], inplace=True)\n",
    "    goes_17_dist_match_df.sort_values(by=['timestamp_converted_rounded'], inplace=True)\n",
    "\n",
    "    first_positive_gt_obs_arr = camera_df.groupby(by='event_name').apply(fetch_first_positive_obs)\n",
    "    \n",
    "    for _, obs in first_positive_gt_obs_arr.iterrows():\n",
    "        first_smokeynet_obs = camera_df.loc[(camera_df.datetime_rounded >= obs.datetime_rounded) & (camera_df.image_pred == 1) & (camera_df.event_name == obs.event_name)]\n",
    "        if len(first_smokeynet_obs) != 0: first_smokeynet_obs = first_smokeynet_obs.iloc[0]['datetime_rounded']\n",
    "        else: first_smokeynet_obs = None\n",
    "        first_goes16_record = goes_16_dist_match_df.loc[goes_16_dist_match_df.timestamp_converted_rounded >= obs.datetime_rounded].iloc[0]\n",
    "        first_goes16_obs = first_goes16_record['timestamp_converted_rounded']\n",
    "        first_goes16_code = first_goes16_record['Code']\n",
    "        first_goes17_record = goes_17_dist_match_df.loc[goes_17_dist_match_df.timestamp_converted_rounded >= obs.datetime_rounded].iloc[0]\n",
    "        first_goes17_obs = first_goes16_record['timestamp_converted_rounded']\n",
    "        first_goes17_code = first_goes17_record['Code']\n",
    "        obs_list.append([camera, obs.event_name, obs.datetime_rounded, first_smokeynet_obs, first_goes16_obs, first_goes17_obs, first_goes16_code, first_goes17_code])\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-06 18:32:00+00:00\n",
      "2020-08-29 17:52:00+00:00\n",
      "2021-01-13 21:14:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Test Cell --> No useful obs\n",
    "camera_df.tail()\n",
    "df_labels_filtered[df_labels_filtered[\"camera_name\"].str.contains(unique_cameras[10])].tail()\n",
    "# Camera df actually contains both the filter_first_probabiity blocks\n",
    "for _, obs in camera_df.groupby(by='event_name').apply(fetch_first_positive_obs).iterrows():\n",
    "    # p (obs.datetime_rounded)\n",
    "    p (camera_df.loc[(camera_df.datetime_rounded >= obs.datetime_rounded)\n",
    "        & (camera_df.image_pred == 1) \n",
    "        & (camera_df.event_name == obs.event_name)].iloc[0]['datetime_rounded'])\n",
    "    # [['datetime_rounded', 'image_gt', 'image_pred']]\n",
    "    # p (camera_df.columns)\n",
    "\n",
    "# camera_df.image_pred.value_counts()\n",
    "# obs_list\n",
    "\n",
    "# Add code for first obs!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/processed/obs_list_times.tsv', 'w') as ol:\n",
    "    ol.write(\"Mapping of first smokey net gt = 1, and first goes observation after that timestamp\\n\")\n",
    "    header = \"\\t\".join(['camera', 'event_name', 'gt_ts', 'smokey_ts', 'goes_16_ts', 'goes_17_ts', 'goes16_code', 'goes17_code', '(smokey-gt) min', '(goes16-gt) min', '(goes17-gt) min'])\n",
    "    ol.write(f\"{header}\\n\")\n",
    "    for obs in obs_list:\n",
    "        smokey_temp = [str((obs[3] - obs[2]).seconds/60) if obs[3] is not None else '']\n",
    "        temp = [str((obs[4] - obs[2]).seconds/60), str((obs[5] - obs[2]).seconds/60)]\n",
    "        x = obs[:2] + [x.ctime() if x is not None else '' for x in obs[2:-2]] + [str(x) for x in obs[-2:]] + smokey_temp + temp\n",
    "        out_str = \"\\t\".join(x)\n",
    "        ol.write(f\"{out_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 136\n",
      "69 136\n"
     ]
    }
   ],
   "source": [
    "# Smokey vs GOES 16\n",
    "obs_list_time_diff = [(x[3] - x[2]).seconds/60 for x in obs_list]\n",
    "sorted(obs_list_time_diff, reverse=True)\n",
    "print (sum([1 if x < 60 else 0 for x in obs_list_time_diff]), len(obs_list_time_diff))\n",
    "\n",
    "# Smokey vs GOES 17\n",
    "obs_list_time_diff = [(x[4] - x[2]).seconds/60 for x in obs_list]\n",
    "sorted(obs_list_time_diff, reverse=True)\n",
    "print (sum([1 if x < 60 else 0 for x in obs_list_time_diff]), len(obs_list_time_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average time to detection for each of the three methods wrt first ground truth positive observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time to detection for smokeynet = 3.593984962406015 mins\n",
      "Average time to detection for goes16 = 409.5882352941176 mins\n",
      "Average time to detection for goes17 = 373.0735294117647 mins\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "\n",
    "smokey_avg = mean([(obs[3] - obs[2]).seconds/60 for obs in obs_list if obs[3] is not None])\n",
    "goes16_avg = mean([(obs[4] - obs[2]).seconds/60 for obs in obs_list])\n",
    "goes17_avg = mean([(obs[5] - obs[2]).seconds/60 for obs in obs_list])\n",
    "\n",
    "p (f\"Average time to detection for smokeynet = {smokey_avg} mins\")\n",
    "p (f\"Average time to detection for goes16 = {goes16_avg} mins\")\n",
    "p (f\"Average time to detection for goes17 = {goes17_avg} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to detection std dev for smokeynet = 6.079718031135962 mins\n",
      "Time to detection std dev for goes16 = 521.9363758637895 mins\n",
      "Time to detection std dev for goes17 = 530.4913875271534 mins\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean, std\n",
    "\n",
    "smokey_std = std([(obs[3] - obs[2]).seconds/60 for obs in obs_list if obs[3] is not None])\n",
    "goes16_std = std([(obs[4] - obs[2]).seconds/60 for obs in obs_list])\n",
    "goes17_std = std([(obs[5] - obs[2]).seconds/60 for obs in obs_list])\n",
    "\n",
    "p (f\"Time to detection std dev for smokeynet = {smokey_std} mins\")\n",
    "p (f\"Time to detection std dev for goes16 = {goes16_std} mins\")\n",
    "p (f\"Time to detection std dev for goes17 = {goes17_std} mins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Result Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------+--------+--------+--------+----------+\n",
      "|                                    experiment                                   | smokey | goes16 | goes17 | ensemble |\n",
      "+---------------------------------------------------------------------------------+--------+--------+--------+----------+\n",
      "|           Original join methodology with distance radius 35 (baseline)          | 0.7833 | 0.5179 | 0.5666 |  0.5652  |\n",
      "|                 Sliding Window Forward Join with Offset = 60 min                | 0.7833 | 0.4941 | 0.4799 |  0.5181  |\n",
      "|                Sliding Window Forward Join with Offset = 120 min                | 0.7833 |  0.5   | 0.5015 |  0.5296  |\n",
      "|                Sliding Window Nearest Join with Offset = 120 min                | 0.7833 | 0.5236 | 0.531  |  0.5634  |\n",
      "|                 Sliding Window Nearest Join with Offset = 60 min                | 0.7833 | 0.5236 | 0.531  |  0.5634  |\n",
      "|         Sliding Window Nearest Join with Offset = 60 min without code 15        | 0.7833 | 0.5054 | 0.5283 |  0.5509  |\n",
      "|                 Sliding Window Nearest Join with Offset = 30 min                | 0.7833 | 0.5698 | 0.5634 |  0.6031  |\n",
      "|                 Sliding Window Nearest Join with Offset = 20 min                | 0.7833 | 0.5971 | 0.5884 |  0.6264  |\n",
      "| Sliding Window Nearest Join with Offset = 20 min without code 15 - same as prev | 0.7833 | 0.5971 | 0.5884 |  0.6264  |\n",
      "|                 Sliding Window Nearest Join with Offset = 10 min                | 0.7833 | 0.6055 | 0.6066 |  0.6304  |\n",
      "|                 Sliding Window Nearest Join with Offset = 5 min                 | 0.7833 | 0.5959 | 0.6089 |  0.6198  |\n",
      "+---------------------------------------------------------------------------------+--------+--------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "header = ['experiment', 'smokey', 'goes16', 'goes17', 'ensemble']\n",
    "result_table = PrettyTable(header)\n",
    "data = [\n",
    "    ['Original join methodology with distance radius 35 (baseline)', 0.7833, 0.5179, 0.5666, 0.5652],\n",
    "    ['Sliding Window Forward Join with Offset = 60 min', 0.7833, 0.4941, 0.4799, 0.5181],\n",
    "    ['Sliding Window Forward Join with Offset = 120 min', 0.7833, 0.5, 0.5015, 0.5296],\n",
    "    ['Sliding Window Nearest Join with Offset = 120 min', 0.7833, 0.5236, 0.5310, 0.5634],\n",
    "    ['Sliding Window Nearest Join with Offset = 60 min', 0.7833, 0.5236, 0.5310, 0.5634],\n",
    "    ['Sliding Window Nearest Join with Offset = 60 min without code 15', 0.7833, 0.5054, 0.5283, 0.5509],\n",
    "    ['Sliding Window Nearest Join with Offset = 30 min', 0.7833, 0.5698, 0.5634, 0.6031],\n",
    "    ['Sliding Window Nearest Join with Offset = 20 min', 0.7833, 0.5971, 0.5884, 0.6264],\n",
    "    ['Sliding Window Nearest Join with Offset = 20 min without code 15 - same as prev', 0.7833, 0.5971, 0.5884, 0.6264],\n",
    "    ['Sliding Window Nearest Join with Offset = 10 min', 0.7833, 0.6055, 0.6066, 0.6304],\n",
    "    ['Sliding Window Nearest Join with Offset = 5 min', 0.7833, 0.5959, 0.6089, 0.6198],\n",
    "]\n",
    "result_table.add_rows(data)\n",
    "print (result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('smokey')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afe615d3e7b8e36a1b63b69c45193ee0f50b2887d76ad336f7f33d5b9a253dea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
